{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94ca9888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from google.cloud import aiplatform \n",
    "from google.cloud import firestore\n",
    "from google.cloud.aiplatform_v1.types import IndexDatapoint\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92322658",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./data_scraping.ipynb\n",
    "%run ./data_retrieval.ipynb\n",
    "%run ./data_augmentation.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235ebb20",
   "metadata": {},
   "source": [
    "# Google Cloud and Gemini configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f4d2dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "HEADERS = {'User-Agent': 'YourName YourCompany your.email@example.com'}\n",
    "TICKER = \"SBET\"\n",
    "TARGET_FORMS = ['10-K', '10-Q']\n",
    "\n",
    "PROJECT_ID = os.environ[\"PROJECT_ID\"]\n",
    "REGION = \"europe-west2\"\n",
    "GEMINI_API_KEY = os.environ[\"GEMINI_API_KEY\"]\n",
    "GEMINI_EMBEDDING_MODEL = \"models/embedding-001\"\n",
    "GEMINI_EMBEDDING_MODEL_DIMENSION = 768 # Gemini embedding-001 model has 768 dimensions\n",
    "GEMINI_GENERATIVE_MODEL = \"gemini-2.5-flash\"\n",
    "COLLECTION_NAME = os.environ[\"COLLECTION_NAME\"]\n",
    "INDEX_NAME = os.environ[\"INDEX_NAME\"]\n",
    "INDEX_ENDPOINT_NAME = os.environ[\"INDEX_ENDPOINT_NAME\"]\n",
    "\n",
    "client = genai.Client(api_key = GEMINI_API_KEY)\n",
    "aiplatform.init(project = PROJECT_ID, location = REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66c2d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the SEC filing data from data_scraping.ipynb\n",
    "\n",
    "cik, company_name = get_cik_and_name_from_ticker()\n",
    "data = get_sec_data(cik)\n",
    "extracted_data = parse_sec_data(data)\n",
    "chunks = get_filing_chunks(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c10daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store metadata on Firestore\n",
    "\n",
    "for key, values in chunks.items():\n",
    "    for i, chunk in enumerate(values):\n",
    "        unique_id = f\"{key}-{i}\"\n",
    "        store_chunk_in_firestore(unique_id, chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc901a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserting datapoints MatchingEngineIndex index: projects/633076006955/locations/europe-west2/indexes/3905025497209241600\n",
      "MatchingEngineIndex index Upserted datapoints. Resource name: projects/633076006955/locations/europe-west2/indexes/3905025497209241600\n"
     ]
    }
   ],
   "source": [
    "# one-time setup\n",
    "index_id = create_and_deploy_vector_index()\n",
    "\n",
    "index_id = get_index_id()\n",
    "datapoints = generate_embeddings_and_prepare_datapoints(chunks)\n",
    "index_resource_name = f\"projects/{PROJECT_ID}/locations/{REGION}/indexes/{index_id}\"\n",
    "\n",
    "if datapoints: \n",
    "    upload_datapoints_to_vertex_ai(index_resource_name, datapoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1ef409",
   "metadata": {},
   "source": [
    "# Generation part of Retrieval-Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7506b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augemnt_and_generate_answer(query, system_prompt, context_chunks, temperature):\n",
    "    \"\"\"\n",
    "    Combines the user's query and the retrieved context into a prompt, then asks the AI model to generate a final answer.\n",
    "    \"\"\"\n",
    "\n",
    "    context_str = \"**CONTEXT:**\\n\" + \"\\n---\\n\".join([chunk['content'] for chunk in context_chunks])\n",
    "    query_formatted = \"\\n\\n---\\n\\n**QUESTION:**\\n\\n\" + query + \"\\n\\n**ANSWER:**\"\n",
    "\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model = GEMINI_GENERATIVE_MODEL,\n",
    "            contents = context_str + query_formatted,\n",
    "            config = types.GenerateContentConfig(\n",
    "                system_instruction = system_prompt,\n",
    "                temperature = temperature\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating answer with Gemini: {e}\")\n",
    "\n",
    "        return\n",
    "\n",
    "def create_safe_filename(query):\n",
    "    \"\"\"Helper function to create a short, safe filename from a user query.\"\"\"\n",
    "\n",
    "    # Remove special characters\n",
    "    query = re.sub(r'[^\\w\\s-]', '', query)\n",
    "    query = re.sub(r'\\s+', '_', query)\n",
    "    # Take the first 5 words and join them\n",
    "    return '_'.join(query.split('_')[:5]).lower()\n",
    "\n",
    "def save_analysis_to_markdown(query, final_ans, context_data):\n",
    "\n",
    "    # naming convention: [TICKER]_[QUERY_SUMMARY]_[YYYY-MM-DD].md\n",
    "    date_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    query_summary = create_safe_filename(query)\n",
    "    filename = f\"{TICKER}_{query_summary}_{date_str.replace('-', '_')}.md\"\n",
    "    \n",
    "    output_dir = \"output\"\n",
    "    os.makedirs(output_dir, exist_ok = True)\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "    # markdown file content and format\n",
    "    content = []\n",
    "    content.append(f\"# Financial Analysis for {TICKER}\")\n",
    "    content.append(f\"**Analysis Date:** {date_str}\")\n",
    "    \n",
    "    content.append(\"\\n## Question:\")\n",
    "    content.append(f\"{query}\")\n",
    "    content.append(\"\\n---\")\n",
    "\n",
    "    content.append(\"\\n## Generated Analysis:\")\n",
    "    content.append(f\"{final_ans}\")\n",
    "    content.append(\"\\n---\")\n",
    "\n",
    "    content.append(\"\\n## Sources\")\n",
    "    for chunk in context_data:\n",
    "        form_type = chunk.get('metadata', {}).get('form_type', 'N/A')\n",
    "        report_date = chunk.get('metadata', {}).get('report_date', 'N/A')\n",
    "        section = chunk.get('metadata', {}).get('section', 'N/A')\n",
    "        url = chunk.get('metadata', {}).get('url', 'N/A') \n",
    "        \n",
    "        content.append(f\"- **Form:** {form_type}\")\n",
    "        content.append(f\"  - **Report Date:** {report_date}\")\n",
    "        content.append(f\"  - **Section:** {section}\")\n",
    "        content.append(f\"  - **URL:** {url}\")\n",
    "\n",
    "    try:\n",
    "        with open(filepath, 'w', encoding = 'utf-8') as f:\n",
    "            f.write(\"\\n\".join(content))\n",
    "        print(f\"\\nSuccessfully saved analysis to: {filepath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving file: {e}\")\n",
    "\n",
    "def ask_question(query, question_no, temperature = 0.2):\n",
    "    \"\"\"\n",
    "    The main function that orchestrates the entire RAG pipeline.\n",
    "    \"\"\"\n",
    "\n",
    "    relevant_ids = find_relevant_chunks(query)\n",
    "    if not relevant_ids:\n",
    "        print(\"Could not find any relevant documents.\")\n",
    "\n",
    "        return\n",
    "    \n",
    "    context_data = retrieve_chunks_from_firestore(relevant_ids)\n",
    "    if not context_data:\n",
    "        print(\"Could not retrieve document content from Firestore.\")\n",
    "\n",
    "        return\n",
    "\n",
    "    final_ans = augemnt_and_generate_answer(query, system_prompt, context_data, temperature)\n",
    "    if final_ans:\n",
    "        save_analysis_to_markdown(query, final_ans, context_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142b2d07",
   "metadata": {},
   "source": [
    "# Prompt management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9d3b44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPTLAYER_API_KEY = os.environ[\"PROMPTLAYER_API_KEY\"]\n",
    "PROMPT_TEMPLATE_IDENTIFIER = os.environ[\"PROMPT_TEMPLATE_IDENTIFIER\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82088d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt():\n",
    "  \n",
    "    url = f\"https://api.promptlayer.com/prompt-templates/{PROMPT_TEMPLATE_IDENTIFIER}\"\n",
    "    headers = {\n",
    "        \"X-API-KEY\": PROMPTLAYER_API_KEY,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers = headers)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    \n",
    "    messages = data.get(\"prompt_template\", {}).get(\"messages\", {})\n",
    "\n",
    "    system_prompt = \"\"\n",
    "    user_prompts = []\n",
    "    for m in messages:\n",
    "        if m.get(\"role\", {}) == \"system\":\n",
    "            system_prompt = m.get(\"content\", [])[0].get(\"text\", \"\")\n",
    "        if m.get(\"role\", {}) == \"user\":\n",
    "            user_prompt = m.get(\"content\", [])[0].get(\"text\", \"\")\n",
    "            user_prompts.append(user_prompt)\n",
    "\n",
    "    if not system_prompt or not user_prompts:\n",
    "        raise ValueError(\"System or User prompts not found in the PromptLayer response.\")\n",
    "\n",
    "    return system_prompt, user_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3355c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 matching document IDs.\n",
      "Successfully retrieved document: SBET-10-Q-0001641172-25-010881-5\n",
      "Successfully retrieved document: SBET-10-Q-0001641172-25-010881-8\n",
      "Successfully retrieved document: SBET-10-Q-0001641172-25-010881-4\n",
      "Successfully retrieved document: SBET-10-Q-0001641172-25-024107-4\n",
      "Successfully retrieved document: SBET-10-Q-0001641172-25-024107-8\n",
      "\n",
      "Successfully saved analysis to: output/SBET_according_to_the_managements_discussion_2025_08_21.md\n",
      "Found 5 matching document IDs.\n",
      "Successfully retrieved document: SBET-10-Q-0001641172-25-010881-8\n",
      "Successfully retrieved document: SBET-10-Q-0001641172-25-024107-8\n",
      "Successfully retrieved document: SBET-10-Q-0001641172-25-010881-5\n",
      "Successfully retrieved document: SBET-10-Q-0001641172-25-024107-16\n",
      "Successfully retrieved document: SBET-10-Q-0001641172-25-010881-4\n",
      "\n",
      "Successfully saved analysis to: output/SBET_summarize_sharplink_gaming_incs_strategy_2025_08_21.md\n",
      "Found 5 matching document IDs.\n",
      "Successfully retrieved document: SBET-10-Q-0001641172-25-024107-13\n",
      "Successfully retrieved document: SBET-10-Q-0001641172-25-010881-5\n",
      "Successfully retrieved document: SBET-10-Q-0001641172-25-024107-16\n",
      "Successfully retrieved document: SBET-10-Q-0001641172-25-010881-8\n",
      "Successfully retrieved document: SBET-10-Q-0001641172-25-024107-8\n",
      "\n",
      "Successfully saved analysis to: output/SBET_identify_the_significant_legal_proceedings_2025_08_21.md\n"
     ]
    }
   ],
   "source": [
    "system_prompt, user_prompts = get_prompt()\n",
    "\n",
    "# final execution function to get the analysis from LLM\n",
    "\n",
    "for i, user_question in enumerate(user_prompts):\n",
    "    user_question_formatted = user_question.format(company_name = company_name)\n",
    "    ask_question(user_question_formatted, i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb3bc4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
