{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e0e9169",
   "metadata": {},
   "source": [
    "# Retrieval part of Retrieval-Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a6f0eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_chunk_in_firestore(chunk_id, chunk_data):\n",
    "\n",
    "    try:\n",
    "        db = firestore.Client(PROJECT_ID)\n",
    "        doc_ref = db.collection(COLLECTION_NAME).document(chunk_id)\n",
    "        if doc_ref.get().exists:\n",
    "            print(f\"Document with ID: {chunk_id} already exists. Skipping write.\")\n",
    "            return\n",
    "        doc_ref.set(chunk_data)\n",
    "        print(f\"Successfully stored document with ID: {chunk_id} in collection '{collection_name}'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error storing document {chunk_id}: {e}\")\n",
    "\n",
    "def get_chunk_in_firestore(chunk_id):\n",
    "\n",
    "    try:\n",
    "        db = firestore.Client(PROJECT_ID)\n",
    "        doc_ref = db.collection(COLLECTION_NAME).document(chunk_id)\n",
    "        doc = doc_ref.get()\n",
    "\n",
    "        if doc.exists:\n",
    "            print(f\"Successfully retrieved document: {chunk_id}\")\n",
    "            \n",
    "            return doc.to_dict()\n",
    "        else:\n",
    "            print(f\"No document found with ID: {chunk_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving document {chunk_id}: {e}\")\n",
    "\n",
    "def create_and_deploy_vector_index():\n",
    "    \"\"\"\n",
    "    Creates a Vertex AI Vector Search Index, an Index Endpoint, and deploys the index.\n",
    "    This is a one-time setup process.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the index\n",
    "    try:\n",
    "        vector_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "            display_name = INDEX_NAME,\n",
    "            dimensions = GEMINI_EMBEDDING_MODEL_DIMENSION,\n",
    "            approximate_neighbors_count = 150,\n",
    "            distance_measure_type = \"DOT_PRODUCT_DISTANCE\",\n",
    "            index_update_method = \"STREAM_UPDATE\"\n",
    "        )\n",
    "        index_id = vector_index.resource_name.split(\"/\")[-1]\n",
    "\n",
    "    except Exception as e:\n",
    "        if \"already exists\" in str(e):\n",
    "            print(f\"Index '{INDEX_NAME}' already exists. Reusing it.\")\n",
    "        else:\n",
    "            raise Exception(e)\n",
    "    \n",
    "    # Create an Index Endpoint\n",
    "    try:\n",
    "        index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "            display_name = INDEX_ENDPOINT_NAME, public_endpoint_enabled = True\n",
    "        )\n",
    "    except Exception as e:\n",
    "        if \"already exists\" in str(e):\n",
    "            print(f\"Endpoint '{INDEX_ENDPOINT_NAME}' already exists. Reusing it.\")\n",
    "            index_endpoint = aiplatform.MatchingEngineIndexEndpoint.list(filter = f'display_name=\"{INDEX_ENDPOINT_NAME}\"')[0]\n",
    "        else:\n",
    "            raise Exception(e)\n",
    "\n",
    "    # Deploy the Index to the Endpoint\n",
    "    try:\n",
    "        # A unique ID for this deployment\n",
    "        deployed_index_id = f\"gemini_deployed_{int(time.time())}\" \n",
    "        index_endpoint.deploy_index(\n",
    "            index = vector_index, deployed_index_id = deployed_index_id\n",
    "        )\n",
    "    except Exception as e:\n",
    "        if \"has been deployed\" in str(e):\n",
    "            print(\"Index is already deployed to this endpoint.\")\n",
    "        else:\n",
    "            raise Exception(e)\n",
    "\n",
    "    return index_id\n",
    "\n",
    "def get_index_id():\n",
    "\n",
    "    try:\n",
    "        indexes = aiplatform.MatchingEngineIndex.list(\n",
    "            filter = f'display_name=\"{INDEX_NAME}\"'\n",
    "        )\n",
    "        index = indexes[0].resource_name.split(\"/\")[-1]\n",
    "        \n",
    "        return index\n",
    "\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"An error occurred: {e}\")\n",
    "\n",
    "def generate_embeddings_and_prepare_datapoints(chunks):\n",
    "    \"\"\"\n",
    "    Takes a list of chunk dictionaries, generates an embedding for each using Gemini,\n",
    "    and formats them for uploading to Vertex AI Vector Search.\n",
    "    \"\"\"\n",
    "\n",
    "    datapoints = []\n",
    "    for key, values in chunks.items():\n",
    "        for i, chunk in enumerate(values):\n",
    "            try:\n",
    "                response = client.models.embed_content(\n",
    "                    model = GEMINI_EMBEDDING_MODEL,\n",
    "                    contents = chunk[\"content\"],\n",
    "                    config = types.EmbedContentConfig(task_type = \"RETRIEVAL_DOCUMENT\"),\n",
    "                ).embeddings\n",
    "                embedding_vector = response[0].values\n",
    "\n",
    "                # Create the datapoint structure required by Vertex AI\n",
    "                # store unique id and embedding only\n",
    "                datapoint = IndexDatapoint(\n",
    "                    datapoint_id = f\"{key}-{i}\",\n",
    "                    feature_vector = embedding_vector\n",
    "                )\n",
    "                datapoints.append(datapoint)\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating embedding for chunk {i}: {e}\")\n",
    "                continue\n",
    "\n",
    "    return datapoints\n",
    "\n",
    "def upload_datapoints_to_vertex_ai(index_resource_name, datapoints):\n",
    "\n",
    "    updated_dense_count = 0\n",
    "    try:\n",
    "        index = aiplatform.MatchingEngineIndex(index_name = index_resource_name)\n",
    "        index.upsert_datapoints(datapoints = datapoints)\n",
    "    except Exception as e:\n",
    "        raise Exception(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3646d8d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
