{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eceb5890",
   "metadata": {},
   "source": [
    "# Get and clean SEC filing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6870a1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cik_and_name_from_ticker():\n",
    "\n",
    "    url = \"https://www.sec.gov/files/company_tickers.json\"\n",
    "    try:\n",
    "        response = requests.get(url, headers = HEADERS)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        for _, d in data.items():\n",
    "            if d['ticker'] == TICKER.upper():\n",
    "                cik = str(d['cik_str'])\n",
    "                cik = cik.zfill(len(cik) + 3)\n",
    "                company_name = d['title']\n",
    "                \n",
    "        return cik, company_name\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "\n",
    "def get_sec_data(cik):\n",
    "\n",
    "    url = f\"https://data.sec.gov/submissions/CIK{cik}.json\"\n",
    "    try:\n",
    "        response = requests.get(url, headers = HEADERS)\n",
    "        response.raise_for_status() \n",
    "        data = response.json()\n",
    "\n",
    "        return data\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "\n",
    "def parse_sec_data(data):\n",
    "\n",
    "    filing_data = data.get(\"filings\", {}).get(\"recent\", {})\n",
    "    if not filing_data:\n",
    "        raise Exception(\"No filing data found.\")\n",
    "\n",
    "    extracted_data = []\n",
    "    num_filings = len(filing_data.get(\"form\", []))\n",
    "    if num_filings:\n",
    "        for i in range(num_filings):\n",
    "            form_type = filing_data.get(\"form\", [])[i]\n",
    "            if form_type in TARGET_FORMS:\n",
    "                try:\n",
    "                    accession_number = filing_data.get('accessionNumber', [])[i]\n",
    "                    primary_document = filing_data.get('primaryDocument', [])[i]\n",
    "                    filing_date = filing_data.get('filingDate', [])[i]\n",
    "                    report_date = filing_data.get('reportDate', [])[i]\n",
    "\n",
    "                    filing_details = {\n",
    "                        'form_type': form_type,\n",
    "                        'accession_number': accession_number,\n",
    "                        'primary_document': primary_document,\n",
    "                        'filing_date': filing_date,\n",
    "                        'report_date': report_date\n",
    "                    }\n",
    "                    extracted_data.append(filing_details)\n",
    "\n",
    "                except IndexError:\n",
    "                    print(f\"Warning: Data inconsistency at index {i}. Skipping this filing.\")\n",
    "                    continue\n",
    "    return extracted_data\n",
    "\n",
    "def construct_sec_url(cik, filing_details):\n",
    "\n",
    "    url = \"https://www.sec.gov/Archives/edgar/data\"\n",
    "    target_cik = cik.lstrip(\"0\")\n",
    "    accession_number = filing_details.get(\"accession_number\", \"\").replace(\"-\", \"\")\n",
    "    primary_document = filing_details.get(\"primary_document\", \"\")\n",
    "    \n",
    "    if accession_number and primary_document:\n",
    "        url = f\"{url}/{target_cik}/{accession_number}/{primary_document}\"\n",
    "    else:\n",
    "        raise Exception(\"Info is missing.\")\n",
    "\n",
    "    return url\n",
    "\n",
    "def get_html_text(url):\n",
    "\n",
    "    try:\n",
    "        res = requests.get(url, headers = HEADERS)\n",
    "        res.raise_for_status()\n",
    "        html_text = res.text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "\n",
    "    return html_text\n",
    "\n",
    "def html_table_to_markdown(table_tag):\n",
    "    \"\"\"\n",
    "    Converts a BeautifulSoup table tag into a Markdown formatted string.\n",
    "    This helps preserve the structure of financial data for the LLM.\n",
    "    \"\"\"\n",
    "\n",
    "    markdown_lines = []\n",
    "    # process table headers\n",
    "    headers = [th.get_text(strip = True).replace(\"\\n\", \"\") for th in table_tag.find_all(\"th\")]\n",
    "\n",
    "    # calculate the space between cells?\n",
    "    if headers:\n",
    "        markdown_lines.append(\"| \" + \" | \".join(headers) + \" |\")\n",
    "        markdown_lines.append(\"| \" + \" | \".join([\"---\"] * len(headers)) + \" |\")\n",
    "\n",
    "    # process table rows\n",
    "    for row in table_tag.find_all(\"tr\"):\n",
    "        cells = [td.get_text(strip = True).replace(\"\\n\", \"\") for td in row.find_all([\"td\", \"th\"])]\n",
    "        # only add rows that have content and match the header count if headers exist\n",
    "        if cells and (not headers or len(cells) == len(headers)):\n",
    "            markdown_lines.append(\"| \" + \" | \".join(cells) + \" |\")\n",
    "\n",
    "    return \"\\n\\n\" + \"\\n\".join(markdown_lines) + \"\\n\\n\" \n",
    "\n",
    "def clean_html(html_text):\n",
    "\n",
    "    if not html_text:\n",
    "        return \"\"\n",
    "\n",
    "    soup = BeautifulSoup(html_text, \"lxml\")\n",
    "\n",
    "    # decompose (completely remove) all script, style, and other non-content tags\n",
    "    for tag in soup(['script', 'style', 'header', 'footer', 'nav']):\n",
    "        tag.decompose()\n",
    "\n",
    "    # convert tables to Markdown and replace the original table tag\n",
    "    for table in soup.find_all(\"table\"):\n",
    "        markdown_text_tag = soup.new_string(html_table_to_markdown(table))\n",
    "        table.replace_with(markdown_text_tag)\n",
    "\n",
    "    text = soup.get_text(separator = \"\\n\", strip = True)\n",
    "    # remove excessive blank lines to make it more readable\n",
    "    cleaned_text = re.sub(r'\\n\\n+', '\\n\\n', text)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "def chunk_filing_by_section(cleaned_text, metadata):\n",
    "\n",
    "    pattern = r'(?i)(item\\s*\\d+[a-z]?\\.?)'\n",
    "    parts = re.split(pattern, cleaned_text)\n",
    "\n",
    "    chunks = []\n",
    "\n",
    "    intro_content = parts[0].strip()\n",
    "    if len(intro_content.split()) > 20:\n",
    "        chunks.append({\n",
    "            \"content\": intro_content,\n",
    "            \"metadata\": {**metadata, \"section\": \"Introduction\"}\n",
    "        })\n",
    "\n",
    "    # The rest of the list is ['Item 1.', 'Content of Item 1...', 'Item 1A.', 'Content of 1A...']\n",
    "    # We iterate through them in pairs.\n",
    "    for i in range(1, len(parts), 2):\n",
    "        header = parts[i].strip()\n",
    "        content = parts[i + 1].strip() if (i + 1) < len(parts) else \"\"\n",
    "\n",
    "        chunk_content = f\"{header}\\n\\n{content}\"\n",
    "\n",
    "        if len(content.split()) > 20:\n",
    "            chunk_obj = {\n",
    "                \"content\": chunk_content,\n",
    "                \"metadata\": {**metadata, \"section\": header}\n",
    "            }\n",
    "            chunks.append(chunk_obj)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def get_filing_chunks(extracted_data):\n",
    "\n",
    "    chunks = dict()\n",
    "    if extracted_data:\n",
    "        for filing in extracted_data:\n",
    "            url = construct_sec_url(cik, filing)\n",
    "            filing[\"url\"] = url\n",
    "            html_text = get_html_text(url)\n",
    "            cleaned_text = clean_html(html_text)\n",
    "            chunk = chunk_filing_by_section(cleaned_text, filing)\n",
    "            id = f\"{TICKER}-{chunk[0]['metadata']['form_type']}-{chunk[0]['metadata']['accession_number']}\" # identifier for a filing\n",
    "            chunks[id] = chunk\n",
    "        \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17c4815",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
